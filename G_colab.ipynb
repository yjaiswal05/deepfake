{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yjaiswal05/deepfake/blob/master/G_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_gtFoV8BuRx"
      },
      "source": [
        "This is a simple example of SimSwap on processing video with multiple faces. You can change the codes for inference based on our other scripts for image or single face swapping.\n",
        "\n",
        "Code path: https://github.com/neuralchen/SimSwap\n",
        "\n",
        "Paper path: https://arxiv.org/pdf/2106.06340v1.pdf or https://dl.acm.org/doi/10.1145/3394171.3413630"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Y1RfpzsCAl9"
      },
      "source": [
        "## make sure you are using a runtime with GPU\n",
        "## you can check at Runtime/Change runtime type in the top bar.\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Qzzx2UpDkqw"
      },
      "source": [
        "## Installation\n",
        "\n",
        "All file changes made by this notebook are temporary. \n",
        "You can try to mount your own google drive to store files if you want.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA_4CeWZCHLP"
      },
      "source": [
        "!git clone https://github.com/neuralchen/SimSwap\n",
        "!cd SimSwap && git pull"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5K4au_UCkKn"
      },
      "source": [
        "!pip install insightface==0.2.1 onnxruntime moviepy\n",
        "!pip install googledrivedownloader\n",
        "!pip install imageio==2.4.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQ7ZoIbLFCye"
      },
      "source": [
        "import os\n",
        "os.chdir(\"SimSwap\")\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLti1J0pEFjJ"
      },
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader\n",
        "\n",
        "### it seems that google drive link may not be permenant, you can find this ID from our open url.\n",
        "# GoogleDriveDownloader.download_file_from_google_drive(file_id='1TLNdIufzwesDbyr_nVTR7Zrx9oRHLM_N',\n",
        "#                                     dest_path='./arcface_model/arcface_checkpoint.tar')\n",
        "# GoogleDriveDownloader.download_file_from_google_drive(file_id='1PXkRiBUYbu1xWpQyDEJvGKeqqUFthJcI',\n",
        "#                                     dest_path='./checkpoints.zip')\n",
        "\n",
        "!wget -P ./arcface_model https://github.com/neuralchen/SimSwap/releases/download/1.0/arcface_checkpoint.tar\n",
        "!wget https://github.com/neuralchen/SimSwap/releases/download/1.0/checkpoints.zip\n",
        "!unzip ./checkpoints.zip  -d ./checkpoints\n",
        "!wget -P ./parsing_model/checkpoint https://github.com/neuralchen/SimSwap/releases/download/1.0/79999_iter.pth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSRnK5V4HI-k"
      },
      "source": [
        "## You can upload filed manually\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "\n",
        "### Now onedrive file can be downloaded in Colab directly!\n",
        "### If the link blow is not permanent, you can just download it from the \n",
        "### open url(can be found at [our repo]/doc/guidance/preparation.md) and copy the assigned download link here.\n",
        "### many thanks to woctezuma for this very useful help\n",
        "!wget --no-check-certificate \"https://sh23tw.dm.files.1drv.com/y4mmGiIkNVigkSwOKDcV3nwMJulRGhbtHdkheehR5TArc52UjudUYNXAEvKCii2O5LAmzGCGK6IfleocxuDeoKxDZkNzDRSt4ZUlEt8GlSOpCXAFEkBwaZimtWGDRbpIGpb_pz9Nq5jATBQpezBS6G_UtspWTkgrXHHxhviV2nWy8APPx134zOZrUIbkSF6xnsqzs3uZ_SEX_m9Rey0ykpx9w\" -O antelope.zip\n",
        "!unzip ./antelope.zip -d ./insightface_func/models/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsGmIMxLVxyO"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfSsND36EMvn"
      },
      "source": [
        "import cv2\n",
        "import torch\n",
        "import fractions\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from models.models import create_model\n",
        "from options.test_options import TestOptions\n",
        "from insightface_func.face_detect_crop_multi import Face_detect_crop\n",
        "from util.videoswap import video_swap\n",
        "from util.add_watermark import watermark_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxSbZ2EDNDlf"
      },
      "source": [
        "transformer = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "transformer_Arcface = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "detransformer = transforms.Compose([\n",
        "        transforms.Normalize([0, 0, 0], [1/0.229, 1/0.224, 1/0.225]),\n",
        "        transforms.Normalize([-0.485, -0.456, -0.406], [1, 1, 1])\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwJOwR9LNKRz"
      },
      "source": [
        "opt = TestOptions()\n",
        "opt.initialize()\n",
        "opt.parser.add_argument('-f') ## dummy arg to avoid bug\n",
        "opt = opt.parse()\n",
        "opt.pic_a_path = './demo_file/Iron_man.jpg' ## or replace it with image from your own google drive\n",
        "opt.video_path = './demo_file/multi_people_1080p.mp4' ## or replace it with video from your own google drive\n",
        "opt.output_path = './output/demo.mp4'\n",
        "opt.temp_path = './tmp'\n",
        "opt.Arc_path = './arcface_model/arcface_checkpoint.tar'\n",
        "opt.isTrain = False\n",
        "opt.use_mask = True  ## new feature up-to-date\n",
        "\n",
        "crop_size = opt.crop_size\n",
        "\n",
        "torch.nn.Module.dump_patches = True\n",
        "model = create_model(opt)\n",
        "model.eval()\n",
        "\n",
        "app = Face_detect_crop(name='antelope', root='./insightface_func/models')\n",
        "app.prepare(ctx_id= 0, det_thresh=0.6, det_size=(640,640))\n",
        "\n",
        "with torch.no_grad():\n",
        "    pic_a = opt.pic_a_path\n",
        "    # img_a = Image.open(pic_a).convert('RGB')\n",
        "    img_a_whole = cv2.imread(pic_a)\n",
        "    img_a_align_crop, _ = app.get(img_a_whole,crop_size)\n",
        "    img_a_align_crop_pil = Image.fromarray(cv2.cvtColor(img_a_align_crop[0],cv2.COLOR_BGR2RGB)) \n",
        "    img_a = transformer_Arcface(img_a_align_crop_pil)\n",
        "    img_id = img_a.view(-1, img_a.shape[0], img_a.shape[1], img_a.shape[2])\n",
        "\n",
        "    # convert numpy to tensor\n",
        "    img_id = img_id.cuda()\n",
        "\n",
        "    #create latent id\n",
        "    img_id_downsample = F.interpolate(img_id, size=(112,112))\n",
        "    latend_id = model.netArc(img_id_downsample)\n",
        "    latend_id = latend_id.detach().to('cpu')\n",
        "    latend_id = latend_id/np.linalg.norm(latend_id,axis=1,keepdims=True)\n",
        "    latend_id = latend_id.to('cuda')\n",
        "\n",
        "    video_swap(opt.video_path, latend_id, model, app, opt.output_path, temp_results_dir=opt.temp_path, use_mask=opt.use_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rty2GsyZZrI6"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}